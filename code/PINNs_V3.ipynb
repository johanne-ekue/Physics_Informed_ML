{"cells":[{"cell_type":"markdown","metadata":{"id":"1b5HNGo7LvOJ"},"source":["# A Physics-Informed Neural Networks for System Identification\n","# Case Study: The Simple Pendulum\n","\n","\n","## Author (put your details)\n"," + Johanne Naa Ayeley Ekue\n","     + Researcher \n","     + [Github Physics Project]https://github.com/johanne-ekue\n","     + Email: jnae.ekue@gmail.com\n","     \n","     \n","\n","\n","## Objectives (work on this)\n","\n","\n","+ Learn how to solve ODEs with neural networks using Physics.\n","+ See how the simulated neural network and physics based neural networks.\n","+ Introduce the problem of spectral bias in DNN's and see how we can solve it.\n","\n","## References (put the papers you read here the same way)\n","\n","+ [Artificial Neural Networks for Solving Ordinary and Partial Differential Equations](https://arxiv.org/pdf/physics/9705023.pdf)\n","+ [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n","+ [On the Spectral Bias of Neural Networks](http://proceedings.mlr.press/v97/rahaman19a/rahaman19a.pdf)\n","+ [Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains](https://arxiv.org/pdf/2006.10739.pdf)\n","\n","\n","<b>copy this line and edit this for bold text</b>"]},{"cell_type":"markdown","metadata":{"id":"zhDQvfygLvOU"},"source":["##Single order ODE\n","#Introduction\n","Physics informed neural network has received massive attention in the field of science and engineering. Physics Informed Neural Network(PINN) are neural networks(NN) that encodes model equations, like  Partial differential Equations(PDE), as a component of the neural network(Cuomo,s. et al(2022)).Using neural networks as surrogate models that have been trained using data gathered at a combination of input and output values is fundamentally different from PINNs. PINN has a wide range of potential applications in many fields due to its ability to incorporate physical constraints and laws into the training process of the neural network.Due to its simplicity, PINNs have helped advance several branches of computer science and engineering. PINNs are getting increased attention in the engineering and scientific literature for solving various differential equations with applications in weather modeling, healthcare, manufacturing, and other sectors.(lawal et al 2022).The intelligent and effective simulation and control of intricate real-world systems is becoming more and more crucial in the age of industry 4.0.PINN can also be used to solve problems such as strutural mechanics, fluid dynamics, heat transfer, climate modeling prediictive maintenance, financial modelling,space explorations,data assimilation, and optimization.The PINN approach essentially transforms the difficulty of directly solving the governing equations into a loss function optimization problem in order to identify ODE solutions.\n","\n","PINNs consider the underlying ODE of our dynamic system (damped pendulum), i.e., the physics of the problem, rather than attempting to infer the solution purely from the data.According to Lagaris et al the best parameter values are determined using a neural network, and that the solution of a differential equation is stated as a constant term and an adjustable term with unknown parameters.\n","According to Cuomo,s. et al, physics inforned neural networks can address problems that are described by few data, or noisy experiment observations.\n","This introduces the era of digital twin:Performant and expressive computer simulations models able to seemlessly incorporate physical measurements.(Rosen et al.,2015).According to Mauel A. et al.data based modelling and physical models have limitations and to reduce model bias and bridge the gap  between both model types which includes physics informed neural network.\n","\n","This paper focuses on using Ordinary Differential Equation(ODE) for our physics informed neural network to optimize our dynamical system (damped simple pendulum) to improve it numerically. The underlying physical laws governing the damped pendulum are incorporated into the architecture of the neural network by training the neural network to minimize the loss functions\n","\n","#Methodology\n","The simulation of the damped pendulum of this paper was done by the use of ordinary differential equations.An ordinary differential equation (ODE) is a mathematical equation that relates an independent variable to a function of one variable and its derivatives. It is used to simulate a variety of natural phenomena, including as population expansion, electrical circuits, and chemical reactions. An ODE's solution reveals information on how, given the initial conditions described, the dependent variable changes over time.The order of the highest  differential cooefficient which is involved.When an equation is a polynomial in all the differential coefficient involved, the power to which the highest differential coefficient  is raised is known as the degree of the equation.Differential equations have been solved using a variety of techniques up to now. Some of them generate an array-based solution that contains the value of the solution at a chosen set of points.\n","Others transform the original and represent the result in analytical form using basis-functions.(legaris et al 1997).\n","\n","ODE of the second order:\n","\n","$$\n","\\frac{d^2y}{dx^2} + y ={x^3}\n","$$\n","ODE of the first order:\n","$$\n","{(x +y)^2}\\frac{dy}{dx}=1\n","$$\n","##Simple Pendulum\n","The dynamical system used as a case study for this paper is simple damped pendulum.The pendulum model is a classic model in physics and has important theoretical and practical significane(Jin Wang et al. 2022). A damped simple pendulum is an ideal case because of its deterministics behaviour due to its motion which is determined by its intial conditions and the laws of physics governing its  behavious,its complex behaviour which includes its oscillations, decay and eventually stopping which can be described mathematically using differential equations.The term \"damping\" refers to any impact that has the tendency to dissipate the system's energy through any kind of resistance. The ratio between damping force and relative velocity is represented by the damping coefficient.\n","A simple pendulum is an idealization of a real pendulum. It consists of an infinitely light rigid rod attached to a frictionless pivot point, and a point mass attached to the free end of rigid rod. \n","##Ordinary differential equation\n","The Ode of the damped pendulum considered in the model is\n","\n","$$\n","\\dot{\\omega} = (\\frac{-b}{m})*ω + \\frac{g}{l}sin\\theta\n","$$\n","where:\n","$$\n","\\dot{\\omega} =\\frac{d^2\\theta}{dt^2}\n","$$\n","\n","$$\n","{\\omega} =\\frac{d\\theta}{dt}\n","$$\n","The b in the equation is the damping coeffiecient, m is the mass of the mass attached to the rod and the g is the acceleration due gravity,and l is the length of the inelastic string.\n","\n","##Predicting Motion of The Pendulum Using Neural Network\n","Linear regression model is a model that can capture linear relationships between inputs and outputs.\n","Two codes was writen for the motion of the pendulum.Linear regression and neural network were used for the first instance with respect to ODE of the pendulum.The lineare regressiom model is a statiscal approach to model the relationship of our Θ and time for 2o seconds. We obtained a mean squared error which will be further dicussed in the results and analysis sector.The advantage of this method is that it might not work well for non linear relationships has its has a low capacity for capturing interactions between features.\n","\n","##The Neural Network Model\n","A neural network model provides a more complex model that can captire non-linear relationships between inputs and outputs.It has high capacity for capturing complex interactions between features and can handle non-linear relationships.\n","The code written trained a linear regressision model \n","\n","The  code used to simulate the motion of the pendulum was used as a means of  building a neural network model to predict the motion of a damped pendulum. It starts by defining a sequential neural network model with several dense layers. The model takes the input with 3 features, and the output is 2-dimensional (the angle and angular velocity of the pendulum). The model is then compiled using mean squared error as the loss function and Adam optimizer with a specified learning rate and \"amsgrad\" setting. The model is trained using the X_train data for 1000 epochs with a batch size of 2 and a validation split of 1%. The model performance is evaluated using the mean squared error between the predicted and actual test values. The results of the model prediction are plotted and compared to the true values in several different plots to visually assess the performance of the model.\n","This method requires more data and computing resources to train and can be more difficult to optimize compared to a simple linear model.\n","Additionally, it might be prone to overfitting, which means that is memorizes the training data instead of leanring general patterns\n","\n","\n","\n","#Physics Informed Neural Network\n","To illustrate the method used in this paper, consider the first ODE of the damped pendulum.\n","Consider the ode:\n","$$\n","\\frac{d(\\theta, ω)}{dt} = f(\\theta,ω),t)\n","$$\n","with $x \\in R^2 $ and initial conditions (IC):\n","$$\n","x(0) = [\\theta_0,\\omega_0]^T\n","$$\n","We write the trial solution by:\n","$$\n","[\\hat{\\theta_t},\\hat{\\omega_t}]^T = [\\theta_0,\\omega_0]^T +  N(\\theta,\\omega)*dt\n","$$\n","or\n","$$\n","[\\hat{\\theta_t},\\hat{\\omega_t}]^T = ode45([\\theta_0,\\omega_0]^T, N(\\omega, \\theta), \\Delta_t)\n","$$\n","where $N(\\omega, \\theta)$ is a neural network (NN).\n","\n","The solution $[\\hat{\\theta_t},\\hat{\\omega_t}]^T$ automatically satisfies the initial conditions.\n","\n","The loss function we would like to minimize to train the NN is:\n","$$\n","L(\\theta) = \\int_0^1 \\left[\\frac{d(\\theta, ω)}{dt} - f(\\hat{\\theta},\\hat{\\omega},t)\\right]^2dt\n","$$\n","\n","$NB$ The trial solution using the neural network may not give the numeric accuracy of the system. \n","\n","To implement a physics informed neural network (PINN) for a damped simple pendulum that does not depend on time t but rather on the timestep and previous states, we will follow the following steps:\n","\n","Convert the second-order ODE to a system of first-order ODEs.\n","Discretize the governing equations using the fourth-order Runge-Kutta method.\n","Define the loss function for the PINN.\n","Train the PINN using stochastic gradient descent.\n","Step 1: Convert the second-order ODE to a system of first-order ODEs\n","\n","The equation of motion for a damped simple pendulum is given by:\n","\n","$$\n","θ''(t) + b/m * θ'(t) + g/L * sin(θ(t)) = 0\n","$$\n","\n","To convert this second-order ODE to a system of first-order ODEs, we introduce a new variable, ω(t), which represents the angular velocity:\n","\n","$$\n","ω(t) = θ'(t)\n","$$\n","\n","The equation of motion can now be written as a system of two first-order ODEs:\n","\n","$$\n","θ'(t) = ω(t)\n","$$\n","$$\n","ω'(t) = -b/m * ω(t) - g/L * sin(θ(t))\n","$$\n","Step 2: Discretize the governing equations using Runge-Kutta 4\n","\n","To discretize the governing equations using the fourth-order Runge-Kutta method, we will use the following algorithm for each time step:\n","\n","Calculate the intermediate k-values for θ and ω:\n","\n","$\n","k1_{θ} = Δt * ω(t)$\n","\n","$\n","k1_{ω} = Δt * (-b/m * ω(t) - g/L * sin(θ(t)))$\n","\n","$\n","k2_{θ} = Δt * (ω(t) + 0.5 * k1_ω)$\n","\n","$\n","k2_{ω} = Δt * (-b/m * (ω(t) + 0.5 * k1_ω) - g/L * sin(θ(t) + 0.5 * k1_θ))$\n","\n","$\n","k3_{θ} = Δt * (ω(t) + 0.5 * k2_ω)$\n","\n","$\n","k3_{ω} = Δt * (-b/m * (ω(t) + 0.5 * k2_ω) - g/L * sin(θ(t) + 0.5 * k2_θ))$\n","\n","$\n","k4_{θ} = Δt * (ω(t) + k3_ω)$\n","\n","$\n","k4_{ω} = Δt * (-b/m * (ω(t) + k3_ω) - g/L * sin(θ(t) + k3_θ))$\n","\n","\n","Update the state (θ, ω) using the k-values:\n","\n","$$\n","θ(t+Δt) = θ(t) + (1/6)(k1_{θ} + 2k2_{θ} + 2k3_{θ} + k4_{θ})\n","$$\n","$$\n","ω(t+Δt) = ω(t) + (1/6)(k1_{ω} + 2k2_{ω} + 2k3_{ω} + k4_{ω})\n","$$\n","\n","Step 3: Define the loss function for the PINN\n","\n","The loss function for the PINN is defined as the sum of two terms:\n","\n","The mean squared error (MSE) between the predicted and actual values of θ and ω:\n","$$\n","MSE(θ_{pred}, θ_{actual}) = (θ_{pred} - θ_{actual})^2\n","$$\n","$$\n","MSE(ω_{pred}, ω_{actual}) = (ω_{pred} - ω_{actual})^2\n","$$\n","The residual of the governing equations, which should be close to zero if the neural network is accurately representing the physics of the system. To compute this residual, we can evaluate the governing equations at a random set of points within the domain of the system, and then take the MSE between the predicted residual, R_pred, and the actual residual, R_actual:\n","\n","$$\n","R1_{pred} = θ'(t) - ω(t)\n","$$\n","$$\n","R2_{pred} = ω'(t) + b/m * ω(t) + g/L * sin(θ(t))\n","$$\n","$$\n","R1_{actual} = R2_{actual} = 0\n","$$\n","\n","The total loss function is the sum of these three terms:\n","$$\n","Loss = MSE(θ_{pred}, θ_{actual})$$$$ \n","      + MSE(ω_{pred}, ω_{actual})$$$$ \n","      + MSE(R1_{pred}, R1_{actual})$$$$ \n","      + MSE(R2_{pred}, R2_{actual})$$$$\n","$$\n","Step 4: Train the PINN using stochastic gradient descent\n","\n","To train the PINN, we can use stochastic gradient descent to minimize the loss function. We can initialize the neural network with random weights and biases, and then update these parameters using backpropagation. During each iteration of the training process, we randomly sample a set of time steps from the data set and use these as inputs to the neural network. We then compute the predicted values of θ and ω, and use these to compute the loss function. Finally, we update the weights and biases using the gradient of the loss function with respect to the parameters.\n","\n","After training, the PINN should be able to accurately predict the motion of the damped simple pendulum system given its initial state and any external forces acting on it."]},{"cell_type":"markdown","metadata":{"id":"4k9_MtIFHfwh"},"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8725,"status":"ok","timestamp":1681474055398,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"hQDhh7FvMX4n","outputId":"d7169636-2d84-4be2-9b13-fca4912f0d10"},"outputs":[{"output_type":"stream","name":"stdout","text":["We're running Colab\n","Colab: mounting Google drive on  /content/drive\n","Mounted at /content/drive\n","\n","Colab: making sure  /content/drive/My Drive/Colab Notebooks/Phyics_Informed_ML  exists.\n","\n","Colab: Changing directory to  /content/drive/My Drive/Colab Notebooks/Phyics_Informed_ML\n","/content/drive/My Drive/Colab Notebooks/Phyics_Informed_ML\n","/content/drive/My Drive/Colab Notebooks/Phyics_Informed_ML\n","\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"]}],"source":["try:\n","  from google.colab import drive\n","  IN_COLAB=True\n","except:\n","  IN_COLAB=False\n","\n","if IN_COLAB:\n","  print(\"We're running Colab\")\n","\n","if IN_COLAB:\n","  # Mount the Google Drive at mount\n","  mount='/content/drive'\n","  print(\"Colab: mounting Google drive on \", mount)\n","\n","  drive.mount(mount, force_remount=True)\n","\n","  # Switch to the directory on the Google Drive that you want to use\n","  import os\n","  drive_root = mount + \"/My Drive/Colab Notebooks/Phyics_Informed_ML\"\n","  \n","  # Create drive_root if it doesn't exist\n","  create_drive_root = True\n","  if create_drive_root:\n","    print(\"\\nColab: making sure \", drive_root, \" exists.\")\n","    os.makedirs(drive_root, exist_ok=True)\n","  \n","  # Change to the directory\n","  print(\"\\nColab: Changing directory to \", drive_root)\n","  %cd $drive_root\n","  !pwd\n","  !pip install -r requirements.txt\n","  !sudo apt-get autoremove\n","\n","\n","  from IPython.display import JSON\n","  from google.colab import output\n","  from subprocess import getoutput\n","  import os\n","  \n","  #@title jQuery Terminal's [Features](https://terminal.jcubic.pl/)\n","\n","  def shell(command):\n","    if command.startswith('cd'):\n","      path = command.strip().split(maxsplit=1)[1]\n","      os.chdir(path)\n","      return JSON([''])\n","    return JSON([getoutput(command)])\n","  output.register_callback('shell', shell)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1681474055399,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"XXMG61-iAWxY"},"outputs":[],"source":["# Change as you wish\n","if IN_COLAB:\n","  DATASET_FOLDER = './data/dataset/'\n","  DATA_FOLDER = './data/'\n","else:\n","  DATASET_FOLDER = './../data/dataset/'\n","  DATA_FOLDER = './../data/'\n","\n","PENDULUM_DATA = 'pendulum_data.csv'"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"elapsed":2088,"status":"ok","timestamp":1681474094736,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"wuMOHrW0UjFS","outputId":"7422a20f-3761-4097-991a-85ebf3860d8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["device: cpu\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import torch\n","torch.manual_seed(0)\n","import torch.nn as nn\n","import numpy as np\n","np.random.seed(0)\n","from scipy.integrate import solve_ivp\n","import matplotlib.pyplot as plt\n","from tqdm.autonotebook import tqdm\n","from IPython.display import display, clear_output\n","import matplotlib.pyplot as plt\n","from scipy.integrate import odeint\n","from time import perf_counter\n","from functools import partial\n","from PIL import Image\n","import requests\n","import math\n","import time\n","import os\n","import torch.nn.functional as F\n","\n","\n","## check if GPU is available and use it; otherwise use CPU\n","if torch.cuda.is_available():\n","    torch.cuda.set_device(0)\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","torch.backends.cudnn.benchmark = True\n","torch.backends.cudnn.enabled = True\n","\n","torch.tensor([1, 2, 3], device=device) # example tensor created on the device\n","\n","print(f'device: {device}')\n","\n","# Define the parameters\n","m = 1.0 # mass of the pendulum\n","l = 1.0 # length of the pendulum\n","g = 9.8 # acceleration due to gravity\n","b = 0.05 # damping coefficient\n","dt = 0.001 # time step\n","tmax = 10.0 # maximum simulation time\n","\n","# Define the initial conditions\n","theta0 = 0.1 # initial angular displacement\n","omega0 = 0.0 # initial angular velocity\n","\n","# Define Pendulum Dynamic Model\n","def damp_Pen(x, b, g, l, m):\n","     theta=x[0]\n","     omega=x[1]\n","     theta_dot=omega\n","     omega_dot=-((b/m)*(omega))-((g/l)*math.sin(theta));\n","     x_dot=np.array([theta_dot,omega_dot]).reshape(-1,1)\n","     return x_dot\n","\n","def rungekutta4_step(x_Dot, x_prev, dt, args=()):\n","    k1 = x_Dot(x_prev, *args)\n","    k2 = x_Dot(x_prev + k1 * dt/2., *args)\n","    k3 = x_Dot(x_prev + k2 * dt/2., *args)\n","    k4 = x_Dot(x_prev + k3 * dt, *args)\n","    return x_prev + (dt / 6.) * (k1 + 2*k2 + 2*k3 + k4)\n","\n","\n","# Initial conditions\n","x0 = [theta0, omega0]\n","sim_time = 8           # specify simulation time for each epoch\n","sampling_period = 0.001\n","t = torch.linspace(0,sim_time,int(sim_time//sampling_period))\n","\n","# True solution\n","x_t = [np.array(x0).reshape(-1,1)]  \n","\n","# Solving the ODE\n","# x = odeint(damp_Pen,x0,t,args=(b,g,l,m))\n","for idx in range(len(t)-1):\n","  x_t.append(x_t[idx] + damp_Pen(x_t[idx], b, g, l, m)*sampling_period) # Forward Euler\n","x_t = np.array(x_t).reshape(-1,2)\n","\n","# True solution\n","X_t = [np.array(x0).reshape(-1,1)]  \n","\n","for idx in range(len(t)-1):\n","  X_t.append(rungekutta4_step(damp_Pen, X_t[idx], sampling_period, args=(b,g,l,m)))  # Forth order RK\n","X_t = np.array(X_t).reshape(-1,2)\n","\n","# Plot the results\n","plt.figure(figsize=(15,5))\n","plt.plot(t, X_t[:,0],label='Theta_RK4')\n","plt.plot(t, X_t[:,1],label='Omega_RK4')\n","plt.plot(t, x_t[:,0], '-', label='Theta_RK1')\n","plt.plot(t, x_t[:,1], '-', label='Omega_RK1')\n","plt.xlabel('Time')\n","plt.ylabel('Amplitude')\n","plt.legend(loc='best')\n","plt.grid(True)\n","plt.title(f'Simulation of Damped Pendulum {int(1/sampling_period)}Hz' )\n","plt.show()"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":833,"status":"ok","timestamp":1681475266955,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"L7SKH0qjxQer"},"outputs":[],"source":["def rungekutta4_step(x_Dot, x_prev, dt, args=()):\n","    k1 = x_Dot(x_prev, *args)\n","    k2 = x_Dot(x_prev + k1 * dt/2., *args)\n","    k3 = x_Dot(x_prev + k2 * dt/2., *args)\n","    k4 = x_Dot(x_prev + k3 * dt, *args)\n","    return x_prev + (dt / 6.) * (k1 + 2*k2 + 2*k3 + k4)\n","\n","def pendulum_dynamics(state):\n","    v, omega = state\n","    theta_dot = omega\n","    theta = torch.arcsin(v)\n","    omega_dot = (-b/m) * omega - (g/l) * torch.sin(theta)\n","    return torch.stack([theta_dot, omega_dot])\n","\n","class PINN(nn.Module):\n","    def __init__(self, g=g-1, l=l, b=b, m=m):\n","        super(PINN, self).__init__()\n","\n","        # Initialize trainable parameters\n","        self.m = nn.Parameter(torch.tensor(m))\n","        self.l = nn.Parameter(torch.tensor(l))\n","        self.b = nn.Parameter(torch.tensor(b))\n","        self.g = nn.Parameter(torch.tensor(g))\n","        # Initialize neural network layers\n","        self.fc1 = nn.Linear(3, hidden_units)\n","        self.fc2 = nn.Linear(hidden_units, hidden_units)\n","        self.fc3 = nn.Linear(hidden_units, hidden_units)\n","        self.fc4 = nn.Linear(hidden_units, 1)\n","\n","        # # Define trainable 2x2 matrix with first element set to 0 if possible\n","        # self.W = nn.Parameter(torch.zeros_like(self.A))\n","        # # Initialize W using LeCun initialization\n","        # nn.init.normal_(self.W, mean=0, std=np.sqrt(1/8))\n","        # # self.W = nn.Parameter(torch.tensor([[0., 1e-6], [ 1e-6, 1e-6]]))\n","        # # Set first element of W to 0 if possible\n","        # self.W.data[0, 0] = 0.0\n","\n","\n","    def forward(self, x):\n","        # self.W.data[0, 0] = 0.0  # Set first element to 0 if possible\n","        \n","        # Extract variables\n","        v, omega = torch.unsqueeze(x, dim=1)\n","        # theta = torch.atan2(v, torch.sqrt(1 - v**2))\n","        theta = torch.asin(v)\n","        omega_dot = -(self.b/self.m)*omega -(self.g/self.l)*torch.sin(theta)\n","        omega_dot = torch.cat([theta, omega, omega_dot])\n","\n","        # Compute physics-informed predictions\n","        omega_dot = self.fc1(omega_dot)\n","        omega_dot = nn.GELU()(omega_dot)\n","        omega_dot = self.fc2(omega_dot)\n","        omega_dot = nn.GELU()(omega_dot)\n","        omega_dot = self.fc3(omega_dot)\n","        omega_dot = nn.Tanh()(omega_dot)\n","        omega_dot = self.fc4(omega_dot)\n","\n","        return torch.cat([omega, omega_dot]) \n","\n","# define the Lipschitz constant\n","def lipschitz_constant(net, norm='fro'):\n","    # compute the Jacobian matrix\n","    x = torch.randn(2, requires_grad=True)\n","    y = net(x)\n","    J = torch.autograd.functional.jacobian(net, x)\n","    # compute the norm of the Jacobian matrix\n","    L = torch.norm(J, p=norm)\n","    return L\n","\n","def pytorch_rolling_window(x, window_size=10, step_size=1):\n","    # unfold dimension to make our rolling window\n","    return x.unfold(0,window_size,step_size)\n","\n","\n","# Define the parameters of the system\n","m = 0.05   # mass of the pendulum\n","g = 9.81   # acceleration due to gravity\n","l = 1.0    # length of the pendulum\n","b = 0.02   # damping coefficient\n","dt = 0.005  # sampling period\n","\n","hidden_layers = 2 # number of hidden layers\n","hidden_units = 1000 # number hidden units \n","\n","L = 1.0 # Lipschitz constant\n","\n","# Define the time interval and time step\n","t0 = 0.0\n","tmax = 8.0\n","dt = 0.001"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["be39d3cbac794beeb23d06e7868e5dc5","fc7ea469bb7d4e2990368b89482d7b4e","9cffb32eba2d472ab82b6470cb011417","7aaa8d10453d437084d4f5cef5c88c99","c69a4800b38f44e39e796d9451e8bd55","1b4c4a23b1c04d13a3ab1890761721c0","1e4562299a4c4930a43e1a5b8ed5fe3d","a2b608b45c7642bdacc8cc9d21cfb8a3","7c0e9f216d3f4ef2b38a232aa2562456","f1fc1dda3f7e41929d84c603e627e369","888bc668c87c4cb68c5ccea2bdc52630","f5401f892d444da5b69e41387ce11a29","2fcea0e5f2be4ceb83753bc6edbb8f65","292f03a9c29749048ff0e5193aa8838e","12836d060cec4d16bbc246f2b708c940","727068d0f957410c812ed9a812a95251","b285579f36504478bd72fdfba46d7906","d671527d3a4346a7812a86c91584f431","cd7dbceccc274d3aad7525773d1a42f7","0491128113d346478f53e9a51ae911ac","d57074bbb9e64e4dba4c6c03a3734984","86f61fbccbe24c078cdab4acb5c5ab28"]},"id":"wIIGJZw16kRg","executionInfo":{"status":"error","timestamp":1681475461340,"user_tz":-120,"elapsed":191511,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"}},"outputId":"81f3970e-4269-434d-ff1d-254a6804b9b7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be39d3cbac794beeb23d06e7868e5dc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/7999 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5401f892d444da5b69e41387ce11a29"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","\n","loss: tensor(0.0019, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0477, -0.0220]])\n","\n","loss: tensor(0.0018, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0492, -0.0219]])\n","\n","loss: tensor(0.0018, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0506, -0.0217]])\n","\n","loss: tensor(0.0017, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0520, -0.0216]])\n","\n","loss: tensor(0.0017, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0534, -0.0214]])\n","\n","loss: tensor(0.0016, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0547, -0.0213]])\n","\n","loss: tensor(0.0016, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0561, -0.0212]])\n","\n","loss: tensor(0.0015, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0574, -0.0210]])\n","\n","loss: tensor(0.0015, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0587, -0.0209]])\n","\n","loss: tensor(0.0014, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0600, -0.0207]])\n","\n","loss: tensor(0.0014, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0613, -0.0206]])\n","\n","loss: tensor(0.0013, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0626, -0.0204]])\n","\n","loss: tensor(0.0013, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0638, -0.0203]])\n","\n","loss: tensor(0.0012, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0651, -0.0201]])\n","\n","loss: tensor(0.0012, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0663, -0.0199]])\n","\n","loss: tensor(0.0011, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0675, -0.0198]])\n","\n","loss: tensor(0.0011, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0686, -0.0196]])\n","\n","loss: tensor(0.0010, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0698, -0.0195]])\n","\n","loss: tensor(0.0010, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0709, -0.0193]])\n","\n","loss: tensor(0.0009, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0721, -0.0191]])\n","\n","loss: tensor(0.0009, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0732, -0.0190]])\n","\n","loss: tensor(0.0008, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0742, -0.0188]])\n","\n","loss: tensor(0.0007, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0753, -0.0186]])\n","\n","loss: tensor(0.0007, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0763, -0.0184]])\n","\n","loss: tensor(0.0006, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0774, -0.0183]])\n","\n","loss: tensor(0.0006, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0784, -0.0181]])\n","\n","loss: tensor(0.0005, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0794, -0.0179]])\n","\n","loss: tensor(0.0004, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0803, -0.0177]])\n","\n","loss: tensor(0.0004, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0813, -0.0175]])\n","\n","loss: tensor(0.0003, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0822, -0.0173]])\n","\n","loss: tensor(0.0003, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0831, -0.0172]])\n","\n","loss: tensor(0.0002, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0840, -0.0170]])\n","\n","loss: tensor(0.0001, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0849, -0.0168]])\n","\n","loss: tensor(7.4689e-05, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0857, -0.0166]])\n","\n","loss: tensor(1.0435e-05, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0865, -0.0164]])\n","\n","loss: tensor(5.4416e-05, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0870, -0.0162]])\n","\n","loss: tensor(0.0001, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0872, -0.0161]])\n","\n","loss: tensor(0.0002, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0872, -0.0160]])\n","\n","loss: tensor(0.0003, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0869, -0.0159]])\n","\n","loss: tensor(0.0003, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0864, -0.0158]])\n","\n","loss: tensor(0.0004, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0858, -0.0157]])\n","\n","loss: tensor(0.0005, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0850, -0.0157]])\n","\n","loss: tensor(0.0005, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0840, -0.0157]])\n","\n","loss: tensor(0.0006, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0829, -0.0156]])\n","\n","loss: tensor(0.0007, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0817, -0.0156]])\n","\n","loss: tensor(0.0007, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0804, -0.0156]])\n","\n","loss: tensor(0.0008, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0790, -0.0157]])\n","\n","loss: tensor(0.0009, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0775, -0.0157]])\n","\n","loss: tensor(0.0010, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0760, -0.0157]])\n","\n","loss: tensor(0.0010, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0744, -0.0158]])\n","\n","loss: tensor(0.0011, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0728, -0.0158]])\n","\n","loss: tensor(0.0012, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0711, -0.0159]])\n","\n","loss: tensor(0.0012, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0694, -0.0159]])\n","\n","loss: tensor(0.0013, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0677, -0.0160]])\n","\n","loss: tensor(0.0014, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0659, -0.0161]])\n","\n","loss: tensor(0.0015, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0641, -0.0161]])\n","\n","loss: tensor(0.0016, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0623, -0.0162]])\n","\n","loss: tensor(0.0016, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0605, -0.0163]])\n","\n","loss: tensor(0.0017, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0587, -0.0164]])\n","\n","loss: tensor(0.0018, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0569, -0.0165]])\n","\n","loss: tensor(0.0019, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0551, -0.0166]])\n","\n","loss: tensor(0.0020, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0533, -0.0166]])\n","\n","loss: tensor(0.0020, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0515, -0.0167]])\n","\n","loss: tensor(0.0021, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0497, -0.0168]])\n","\n","loss: tensor(0.0022, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0479, -0.0170]])\n","\n","loss: tensor(0.0023, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0461, -0.0171]])\n","\n","loss: tensor(0.0024, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0443, -0.0172]])\n","\n","loss: tensor(0.0024, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0426, -0.0173]])\n","\n","loss: tensor(0.0025, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0408, -0.0174]])\n","\n","loss: tensor(0.0026, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0391, -0.0175]])\n","\n","loss: tensor(0.0027, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0374, -0.0176]])\n","\n","loss: tensor(0.0028, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0357, -0.0177]])\n","\n","loss: tensor(0.0029, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0341, -0.0178]])\n","\n","loss: tensor(0.0030, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0324, -0.0180]])\n","\n","loss: tensor(0.0031, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0308, -0.0181]])\n","\n","loss: tensor(0.0031, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0292, -0.0182]])\n","\n","loss: tensor(0.0032, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0276, -0.0183]])\n","\n","loss: tensor(0.0033, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0260, -0.0185]])\n","\n","loss: tensor(0.0034, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0244, -0.0186]])\n","\n","loss: tensor(0.0035, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0229, -0.0187]])\n","\n","loss: tensor(0.0036, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0214, -0.0189]])\n","\n","loss: tensor(0.0037, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0199, -0.0190]])\n","\n","loss: tensor(0.0038, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0185, -0.0191]])\n","\n","loss: tensor(0.0039, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0170, -0.0193]])\n","\n","loss: tensor(0.0040, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0156, -0.0194]])\n","\n","loss: tensor(0.0041, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0142, -0.0195]])\n","\n","loss: tensor(0.0042, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0129, -0.0197]])\n","\n","loss: tensor(0.0042, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0115, -0.0198]])\n","\n","loss: tensor(0.0043, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0102, -0.0199]])\n","\n","loss: tensor(0.0044, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0089, -0.0201]])\n","\n","loss: tensor(0.0045, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0077, -0.0202]])\n","\n","loss: tensor(0.0046, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0064, -0.0204]])\n","\n","loss: tensor(0.0047, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0052, -0.0205]])\n","\n","loss: tensor(0.0048, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0040, -0.0207]])\n","\n","loss: tensor(0.0049, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0028, -0.0208]])\n","\n","loss: tensor(0.0050, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0017, -0.0210]])\n","\n","loss: tensor(0.0051, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0006, -0.0211]])\n","\n","loss: tensor(0.0052, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9995, -0.0213]])\n","\n","loss: tensor(0.0053, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9984, -0.0214]])\n","\n","loss: tensor(0.0054, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9974, -0.0216]])\n","\n","loss: tensor(0.0055, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9964, -0.0217]])\n","\n","loss: tensor(0.0056, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9954, -0.0219]])\n","\n","loss: tensor(0.0057, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9944, -0.0221]])\n","\n","loss: tensor(0.0059, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9935, -0.0222]])\n","\n","loss: tensor(0.0060, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9925, -0.0224]])\n","\n","loss: tensor(0.0061, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9917, -0.0225]])\n","\n","loss: tensor(0.0062, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9908, -0.0227]])\n","\n","loss: tensor(0.0063, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9900, -0.0229]])\n","\n","loss: tensor(0.0064, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9891, -0.0230]])\n","\n","loss: tensor(0.0065, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9884, -0.0232]])\n","\n","loss: tensor(0.0066, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9876, -0.0234]])\n","\n","loss: tensor(0.0067, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9869, -0.0235]])\n","\n","loss: tensor(0.0068, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9861, -0.0237]])\n","\n","loss: tensor(0.0069, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9855, -0.0239]])\n","\n","loss: tensor(0.0070, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9848, -0.0241]])\n","\n","loss: tensor(0.0071, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9842, -0.0242]])\n","\n","loss: tensor(0.0073, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9836, -0.0244]])\n","\n","loss: tensor(0.0074, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9830, -0.0246]])\n","\n","loss: tensor(0.0075, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9824, -0.0248]])\n","\n","loss: tensor(0.0076, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9819, -0.0249]])\n","\n","loss: tensor(0.0077, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9814, -0.0251]])\n","\n","loss: tensor(0.0078, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9809, -0.0253]])\n","\n","loss: tensor(0.0079, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9804, -0.0255]])\n","\n","loss: tensor(0.0081, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9800, -0.0257]])\n","\n","loss: tensor(0.0082, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9796, -0.0259]])\n","\n","loss: tensor(0.0083, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9792, -0.0260]])\n","\n","loss: tensor(0.0084, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9789, -0.0262]])\n","\n","loss: tensor(0.0085, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9786, -0.0264]])\n","\n","loss: tensor(0.0086, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9783, -0.0266]])\n","\n","loss: tensor(0.0088, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9780, -0.0268]])\n","\n","loss: tensor(0.0089, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9777, -0.0270]])\n","\n","loss: tensor(0.0090, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9775, -0.0272]])\n","\n","loss: tensor(0.0091, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9773, -0.0274]])\n","\n","loss: tensor(0.0092, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9771, -0.0276]])\n","\n","loss: tensor(0.0094, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9770, -0.0278]])\n","\n","loss: tensor(0.0095, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9769, -0.0280]])\n","\n","loss: tensor(0.0096, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9768, -0.0282]])\n","\n","loss: tensor(0.0097, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9767, -0.0284]])\n","\n","loss: tensor(0.0098, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9767, -0.0286]])\n","\n","loss: tensor(0.0100, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9767, -0.0288]])\n","\n","loss: tensor(0.0101, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9767, -0.0290]])\n","\n","loss: tensor(0.0102, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9767, -0.0292]])\n","\n","loss: tensor(0.0103, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9768, -0.0294]])\n","\n","loss: tensor(0.0105, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9769, -0.0296]])\n","\n","loss: tensor(0.0106, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9770, -0.0298]])\n","\n","loss: tensor(0.0107, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9771, -0.0301]])\n","\n","loss: tensor(0.0109, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9773, -0.0303]])\n","\n","loss: tensor(0.0110, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9775, -0.0305]])\n","\n","loss: tensor(0.0111, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9777, -0.0307]])\n","\n","loss: tensor(0.0112, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9780, -0.0309]])\n","\n","loss: tensor(0.0114, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9782, -0.0311]])\n","\n","loss: tensor(0.0115, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9785, -0.0314]])\n","\n","loss: tensor(0.0116, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9788, -0.0316]])\n","\n","loss: tensor(0.0118, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9792, -0.0318]])\n","\n","loss: tensor(0.0119, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9796, -0.0320]])\n","\n","loss: tensor(0.0120, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9800, -0.0323]])\n","\n","loss: tensor(0.0122, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9804, -0.0325]])\n","\n","loss: tensor(0.0123, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9809, -0.0327]])\n","\n","loss: tensor(0.0124, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9813, -0.0330]])\n","\n","loss: tensor(0.0126, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9818, -0.0332]])\n","\n","loss: tensor(0.0127, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9824, -0.0334]])\n","\n","loss: tensor(0.0128, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9829, -0.0337]])\n","\n","loss: tensor(0.0130, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9835, -0.0339]])\n","\n","loss: tensor(0.0131, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9841, -0.0341]])\n","\n","loss: tensor(0.0132, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9848, -0.0344]])\n","\n","loss: tensor(0.0134, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9854, -0.0346]])\n","\n","loss: tensor(0.0135, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9861, -0.0348]])\n","\n","loss: tensor(0.0136, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9868, -0.0351]])\n","\n","loss: tensor(0.0138, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9876, -0.0353]])\n","\n","loss: tensor(0.0139, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9884, -0.0356]])\n","\n","loss: tensor(0.0141, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9892, -0.0358]])\n","\n","loss: tensor(0.0142, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9900, -0.0361]])\n","\n","loss: tensor(0.0143, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9908, -0.0363]])\n","\n","loss: tensor(0.0145, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9917, -0.0366]])\n","\n","loss: tensor(0.0146, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9926, -0.0368]])\n","\n","loss: tensor(0.0148, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9935, -0.0371]])\n","\n","loss: tensor(0.0149, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9945, -0.0373]])\n","\n","loss: tensor(0.0151, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9955, -0.0376]])\n","\n","loss: tensor(0.0152, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9965, -0.0379]])\n","\n","loss: tensor(0.0153, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9975, -0.0381]])\n","\n","loss: tensor(0.0155, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9986, -0.0384]])\n","\n","loss: tensor(0.0156, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-0.9997, -0.0386]])\n","\n","loss: tensor(0.0158, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0008, -0.0389]])\n","\n","loss: tensor(0.0159, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0019, -0.0392]])\n","\n","loss: tensor(0.0161, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0031, -0.0394]])\n","\n","loss: tensor(0.0162, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0043, -0.0397]])\n","\n","loss: tensor(0.0164, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0055, -0.0400]])\n","\n","loss: tensor(0.0165, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0068, -0.0402]])\n","\n","loss: tensor(0.0167, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0080, -0.0405]])\n","\n","loss: tensor(0.0168, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0093, -0.0408]])\n","\n","loss: tensor(0.0170, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0107, -0.0411]])\n","\n","loss: tensor(0.0171, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0120, -0.0413]])\n","\n","loss: tensor(0.0173, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0134, -0.0416]])\n","\n","loss: tensor(0.0174, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0148, -0.0419]])\n","\n","loss: tensor(0.0176, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0163, -0.0422]])\n","\n","loss: tensor(0.0177, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0177, -0.0425]])\n","\n","loss: tensor(0.0179, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0192, -0.0428]])\n","\n","loss: tensor(0.0180, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0207, -0.0430]])\n","\n","loss: tensor(0.0182, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0223, -0.0433]])\n","\n","loss: tensor(0.0183, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0239, -0.0436]])\n","\n","loss: tensor(0.0185, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0255, -0.0439]])\n","\n","loss: tensor(0.0186, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0271, -0.0442]])\n","\n","loss: tensor(0.0188, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0287, -0.0445]])\n","\n","loss: tensor(0.0190, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0304, -0.0448]])\n","\n","loss: tensor(0.0191, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0321, -0.0451]])\n","\n","loss: tensor(0.0193, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0339, -0.0454]])\n","\n","loss: tensor(0.0194, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0356, -0.0457]])\n","\n","loss: tensor(0.0196, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0374, -0.0460]])\n","\n","loss: tensor(0.0197, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0392, -0.0463]])\n","\n","loss: tensor(0.0199, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0411, -0.0466]])\n","\n","loss: tensor(0.0201, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0430, -0.0469]])\n","\n","loss: tensor(0.0202, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0449, -0.0472]])\n","\n","loss: tensor(0.0204, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0468, -0.0475]])\n","\n","loss: tensor(0.0205, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0488, -0.0479]])\n","\n","loss: tensor(0.0207, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0507, -0.0482]])\n","\n","loss: tensor(0.0209, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0528, -0.0485]])\n","\n","loss: tensor(0.0210, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0548, -0.0488]])\n","\n","loss: tensor(0.0212, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0569, -0.0491]])\n","\n","loss: tensor(0.0214, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0590, -0.0494]])\n","\n","loss: tensor(0.0215, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0611, -0.0498]])\n","\n","loss: tensor(0.0217, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0632, -0.0501]])\n","\n","loss: tensor(0.0219, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0654, -0.0504]])\n","\n","loss: tensor(0.0220, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0676, -0.0507]])\n","\n","loss: tensor(0.0222, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0699, -0.0511]])\n","\n","loss: tensor(0.0224, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0721, -0.0514]])\n","\n","loss: tensor(0.0225, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0744, -0.0517]])\n","\n","loss: tensor(0.0227, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0768, -0.0521]])\n","\n","loss: tensor(0.0229, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0791, -0.0524]])\n","\n","loss: tensor(0.0230, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0815, -0.0527]])\n","\n","loss: tensor(0.0232, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0839, -0.0531]])\n","\n","loss: tensor(0.0234, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0863, -0.0534]])\n","\n","loss: tensor(0.0235, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0888, -0.0538]])\n","\n","loss: tensor(0.0237, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0913, -0.0541]])\n","\n","loss: tensor(0.0239, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0938, -0.0545]])\n","\n","loss: tensor(0.0241, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0964, -0.0548]])\n","\n","loss: tensor(0.0242, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.0989, -0.0552]])\n","\n","loss: tensor(0.0244, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1015, -0.0555]])\n","\n","loss: tensor(0.0246, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1042, -0.0559]])\n","\n","loss: tensor(0.0248, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1068, -0.0562]])\n","\n","loss: tensor(0.0249, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1095, -0.0566]])\n","\n","loss: tensor(0.0251, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1123, -0.0569]])\n","\n","loss: tensor(0.0253, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1150, -0.0573]])\n","\n","loss: tensor(0.0255, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1178, -0.0577]])\n","\n","loss: tensor(0.0256, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1206, -0.0580]])\n","\n","loss: tensor(0.0258, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1234, -0.0584]])\n","\n","loss: tensor(0.0260, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1263, -0.0588]])\n","\n","loss: tensor(0.0262, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1292, -0.0591]])\n","\n","loss: tensor(0.0263, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1321, -0.0595]])\n","\n","loss: tensor(0.0265, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1351, -0.0599]])\n","\n","loss: tensor(0.0267, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1381, -0.0603]])\n","\n","loss: tensor(0.0269, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1411, -0.0606]])\n","\n","loss: tensor(0.0271, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1441, -0.0610]])\n","\n","loss: tensor(0.0273, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1472, -0.0614]])\n","\n","loss: tensor(0.0274, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1503, -0.0618]])\n","\n","loss: tensor(0.0276, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1535, -0.0622]])\n","\n","loss: tensor(0.0278, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1566, -0.0626]])\n","\n","loss: tensor(0.0280, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1598, -0.0630]])\n","\n","loss: tensor(0.0282, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1630, -0.0633]])\n","\n","loss: tensor(0.0284, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1663, -0.0637]])\n","\n","loss: tensor(0.0285, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1696, -0.0641]])\n","\n","loss: tensor(0.0287, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1729, -0.0645]])\n","\n","loss: tensor(0.0289, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1763, -0.0649]])\n","\n","loss: tensor(0.0291, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1796, -0.0653]])\n","\n","loss: tensor(0.0293, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1830, -0.0657]])\n","\n","loss: tensor(0.0295, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1865, -0.0661]])\n","\n","loss: tensor(0.0297, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1899, -0.0666]])\n","\n","loss: tensor(0.0299, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1934, -0.0670]])\n","\n","loss: tensor(0.0300, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.1970, -0.0674]])\n","\n","loss: tensor(0.0302, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2005, -0.0678]])\n","\n","loss: tensor(0.0304, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2041, -0.0682]])\n","\n","loss: tensor(0.0306, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2077, -0.0686]])\n","\n","loss: tensor(0.0308, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2114, -0.0691]])\n","\n","loss: tensor(0.0310, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2151, -0.0695]])\n","\n","loss: tensor(0.0312, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2188, -0.0699]])\n","\n","loss: tensor(0.0314, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2225, -0.0703]])\n","\n","loss: tensor(0.0316, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2263, -0.0708]])\n","\n","loss: tensor(0.0318, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2301, -0.0712]])\n","\n","loss: tensor(0.0320, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2340, -0.0716]])\n","\n","loss: tensor(0.0322, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2378, -0.0721]])\n","\n","loss: tensor(0.0324, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2417, -0.0725]])\n","\n","loss: tensor(0.0326, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2457, -0.0729]])\n","\n","loss: tensor(0.0328, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2497, -0.0734]])\n","\n","loss: tensor(0.0330, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2537, -0.0738]])\n","\n","loss: tensor(0.0332, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2577, -0.0743]])\n","\n","loss: tensor(0.0334, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2618, -0.0747]])\n","\n","loss: tensor(0.0336, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2659, -0.0752]])\n","\n","loss: tensor(0.0338, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2700, -0.0756]])\n","\n","loss: tensor(0.0340, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2741, -0.0761]])\n","\n","loss: tensor(0.0342, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2783, -0.0766]])\n","\n","loss: tensor(0.0344, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2826, -0.0770]])\n","\n","loss: tensor(0.0346, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2868, -0.0775]])\n","\n","loss: tensor(0.0348, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2911, -0.0780]])\n","\n","loss: tensor(0.0350, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2954, -0.0784]])\n","\n","loss: tensor(0.0352, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.2998, -0.0789]])\n","\n","loss: tensor(0.0354, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3042, -0.0794]])\n","\n","loss: tensor(0.0356, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3086, -0.0798]])\n","\n","loss: tensor(0.0358, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3131, -0.0803]])\n","\n","loss: tensor(0.0360, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3176, -0.0808]])\n","\n","loss: tensor(0.0362, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3221, -0.0813]])\n","\n","loss: tensor(0.0364, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3267, -0.0818]])\n","\n","loss: tensor(0.0367, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3313, -0.0823]])\n","\n","loss: tensor(0.0369, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3359, -0.0828]])\n","\n","loss: tensor(0.0371, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3406, -0.0832]])\n","\n","loss: tensor(0.0373, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3453, -0.0837]])\n","\n","loss: tensor(0.0375, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3500, -0.0842]])\n","\n","loss: tensor(0.0377, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3547, -0.0847]])\n","\n","loss: tensor(0.0379, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3595, -0.0853]])\n","\n","loss: tensor(0.0381, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3644, -0.0858]])\n","\n","loss: tensor(0.0384, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3693, -0.0863]])\n","\n","loss: tensor(0.0386, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3742, -0.0868]])\n","\n","loss: tensor(0.0388, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3791, -0.0873]])\n","\n","loss: tensor(0.0390, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3841, -0.0878]])\n","\n","loss: tensor(0.0392, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3891, -0.0883]])\n","\n","loss: tensor(0.0394, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3941, -0.0889]])\n","\n","loss: tensor(0.0397, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.3992, -0.0894]])\n","\n","loss: tensor(0.0399, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4043, -0.0899]])\n","\n","loss: tensor(0.0401, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4095, -0.0904]])\n","\n","loss: tensor(0.0403, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4147, -0.0910]])\n","\n","loss: tensor(0.0405, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4199, -0.0915]])\n","\n","loss: tensor(0.0408, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4252, -0.0921]])\n","\n","loss: tensor(0.0410, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4305, -0.0926]])\n","\n","loss: tensor(0.0412, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4358, -0.0931]])\n","\n","loss: tensor(0.0414, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4412, -0.0937]])\n","\n","loss: tensor(0.0417, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4466, -0.0942]])\n","\n","loss: tensor(0.0419, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4520, -0.0948]])\n","\n","loss: tensor(0.0421, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4575, -0.0954]])\n","\n","loss: tensor(0.0423, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4630, -0.0959]])\n","\n","loss: tensor(0.0426, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4686, -0.0965]])\n","\n","loss: tensor(0.0428, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4742, -0.0970]])\n","\n","loss: tensor(0.0430, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4798, -0.0976]])\n","\n","loss: tensor(0.0433, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4855, -0.0982]])\n","\n","loss: tensor(0.0435, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4912, -0.0988]])\n","\n","loss: tensor(0.0437, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.4969, -0.0993]])\n","\n","loss: tensor(0.0439, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5027, -0.0999]])\n","\n","loss: tensor(0.0442, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5085, -0.1005]])\n","\n","loss: tensor(0.0444, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5144, -0.1011]])\n","\n","loss: tensor(0.0447, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5203, -0.1017]])\n","\n","loss: tensor(0.0449, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5262, -0.1023]])\n","\n","loss: tensor(0.0451, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5322, -0.1029]])\n","\n","loss: tensor(0.0454, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5382, -0.1035]])\n","\n","loss: tensor(0.0456, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5443, -0.1041]])\n","\n","loss: tensor(0.0458, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5504, -0.1047]])\n","\n","loss: tensor(0.0461, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5565, -0.1053]])\n","\n","loss: tensor(0.0463, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5627, -0.1059]])\n","\n","loss: tensor(0.0466, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5689, -0.1065]])\n","\n","loss: tensor(0.0468, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5752, -0.1071]])\n","\n","loss: tensor(0.0470, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5815, -0.1078]])\n","\n","loss: tensor(0.0473, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5878, -0.1084]])\n","\n","loss: tensor(0.0475, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.5942, -0.1090]])\n","\n","loss: tensor(0.0478, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6006, -0.1097]])\n","\n","loss: tensor(0.0480, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6071, -0.1103]])\n","\n","loss: tensor(0.0483, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6136, -0.1109]])\n","\n","loss: tensor(0.0485, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6202, -0.1116]])\n","\n","loss: tensor(0.0488, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6268, -0.1122]])\n","\n","loss: tensor(0.0490, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6334, -0.1129]])\n","\n","loss: tensor(0.0493, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6401, -0.1135]])\n","\n","loss: tensor(0.0495, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6468, -0.1142]])\n","\n","loss: tensor(0.0498, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6535, -0.1148]])\n","\n","loss: tensor(0.0500, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6603, -0.1155]])\n","\n","loss: tensor(0.0503, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6672, -0.1162]])\n","\n","loss: tensor(0.0505, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6741, -0.1169]])\n","\n","loss: tensor(0.0508, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6810, -0.1175]])\n","\n","loss: tensor(0.0510, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6880, -0.1182]])\n","\n","loss: tensor(0.0513, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.6950, -0.1189]])\n","\n","loss: tensor(0.0515, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7021, -0.1196]])\n","\n","loss: tensor(0.0518, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7092, -0.1203]])\n","\n","loss: tensor(0.0520, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7164, -0.1210]])\n","\n","loss: tensor(0.0523, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7236, -0.1217]])\n","\n","loss: tensor(0.0526, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7308, -0.1224]])\n","\n","loss: tensor(0.0528, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7381, -0.1231]])\n","\n","loss: tensor(0.0531, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7455, -0.1238]])\n","\n","loss: tensor(0.0534, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7528, -0.1245]])\n","\n","loss: tensor(0.0536, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7603, -0.1252]])\n","\n","loss: tensor(0.0539, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7677, -0.1259]])\n","\n","loss: tensor(0.0542, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7753, -0.1267]])\n","\n","loss: tensor(0.0544, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7829, -0.1274]])\n","\n","loss: tensor(0.0547, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7905, -0.1281]])\n","\n","loss: tensor(0.0550, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.7981, -0.1289]])\n","\n","loss: tensor(0.0552, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8059, -0.1296]])\n","\n","loss: tensor(0.0555, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8136, -0.1304]])\n","\n","loss: tensor(0.0558, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8214, -0.1311]])\n","\n","loss: tensor(0.0560, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8293, -0.1319]])\n","\n","loss: tensor(0.0563, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8372, -0.1326]])\n","\n","loss: tensor(0.0566, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8452, -0.1334]])\n","\n","loss: tensor(0.0569, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8532, -0.1342]])\n","\n","loss: tensor(0.0571, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8613, -0.1349]])\n","\n","loss: tensor(0.0574, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8694, -0.1357]])\n","\n","loss: tensor(0.0577, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8775, -0.1365]])\n","\n","loss: tensor(0.0580, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8858, -0.1373]])\n","\n","loss: tensor(0.0583, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.8940, -0.1381]])\n","\n","loss: tensor(0.0585, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9023, -0.1389]])\n","\n","loss: tensor(0.0588, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9107, -0.1397]])\n","\n","loss: tensor(0.0591, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9191, -0.1405]])\n","\n","loss: tensor(0.0594, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9276, -0.1413]])\n","\n","loss: tensor(0.0597, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9361, -0.1421]])\n","\n","loss: tensor(0.0600, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9447, -0.1429]])\n","\n","loss: tensor(0.0603, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9534, -0.1437]])\n","\n","loss: tensor(0.0605, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9621, -0.1446]])\n","\n","loss: tensor(0.0608, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9708, -0.1454]])\n","\n","loss: tensor(0.0611, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9796, -0.1462]])\n","\n","loss: tensor(0.0614, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9885, -0.1471]])\n","\n","loss: tensor(0.0617, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-1.9974, -0.1479]])\n","\n","loss: tensor(0.0620, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0063, -0.1488]])\n","\n","loss: tensor(0.0623, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0154, -0.1496]])\n","\n","loss: tensor(0.0626, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0244, -0.1505]])\n","\n","loss: tensor(0.0629, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0336, -0.1514]])\n","\n","loss: tensor(0.0632, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0428, -0.1523]])\n","\n","loss: tensor(0.0635, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0520, -0.1531]])\n","\n","loss: tensor(0.0638, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0613, -0.1540]])\n","\n","loss: tensor(0.0641, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0707, -0.1549]])\n","\n","loss: tensor(0.0644, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0801, -0.1558]])\n","\n","loss: tensor(0.0647, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0896, -0.1567]])\n","\n","loss: tensor(0.0650, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.0991, -0.1576]])\n","\n","loss: tensor(0.0653, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.1088, -0.1585]])\n","\n","loss: tensor(0.0656, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.1184, -0.1594]])\n","\n","loss: tensor(0.0660, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.1281, -0.1604]])\n","\n","loss: tensor(0.0663, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.1379, -0.1613]])\n","\n","loss: tensor(0.0666, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.1478, -0.1622]])\n","\n","loss: tensor(0.0669, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.1577, -0.1632]])\n","\n","loss: tensor(0.0672, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.1677, -0.1641]])\n","\n","loss: tensor(0.0675, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.1777, -0.1651]])\n","\n","loss: tensor(0.0678, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.1878, -0.1660]])\n","\n","loss: tensor(0.0682, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.1980, -0.1670]])\n","\n","loss: tensor(0.0685, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.2082, -0.1679]])\n","\n","loss: tensor(0.0688, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.2185, -0.1689]])\n","\n","loss: tensor(0.0691, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.2289, -0.1699]])\n","\n","loss: tensor(0.0695, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.2393, -0.1709]])\n","\n","loss: tensor(0.0698, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.2498, -0.1719]])\n","\n","loss: tensor(0.0701, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.2604, -0.1729]])\n","\n","loss: tensor(0.0705, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.2710, -0.1739]])\n","\n","loss: tensor(0.0708, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.2817, -0.1749]])\n","\n","loss: tensor(0.0711, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.2925, -0.1759]])\n","\n","loss: tensor(0.0715, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.3033, -0.1769]])\n","\n","loss: tensor(0.0718, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.3142, -0.1780]])\n","\n","loss: tensor(0.0721, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.3252, -0.1790]])\n","\n","loss: tensor(0.0725, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.3363, -0.1800]])\n","\n","loss: tensor(0.0728, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.3474, -0.1811]])\n","\n","loss: tensor(0.0731, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.3586, -0.1821]])\n","\n","loss: tensor(0.0735, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.3698, -0.1832]])\n","\n","loss: tensor(0.0738, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.3812, -0.1843]])\n","\n","loss: tensor(0.0742, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.3926, -0.1853]])\n","\n","loss: tensor(0.0745, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.4041, -0.1864]])\n","\n","loss: tensor(0.0749, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.4157, -0.1875]])\n","\n","loss: tensor(0.0752, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.4273, -0.1886]])\n","\n","loss: tensor(0.0756, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.4390, -0.1897]])\n","\n","loss: tensor(0.0759, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.4508, -0.1908]])\n","\n","loss: tensor(0.0763, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.4627, -0.1920]])\n","\n","loss: tensor(0.0767, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.4746, -0.1931]])\n","\n","loss: tensor(0.0770, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.4867, -0.1942]])\n","\n","loss: tensor(0.0774, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.4988, -0.1954]])\n","\n","loss: tensor(0.0777, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.5110, -0.1965]])\n","\n","loss: tensor(0.0781, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.5232, -0.1977]])\n","\n","loss: tensor(0.0785, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.5356, -0.1988]])\n","\n","loss: tensor(0.0789, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.5480, -0.2000]])\n","\n","loss: tensor(0.0792, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.5606, -0.2012]])\n","\n","loss: tensor(0.0796, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.5732, -0.2024]])\n","\n","loss: tensor(0.0800, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.5859, -0.2036]])\n","\n","loss: tensor(0.0804, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.5986, -0.2048]])\n","\n","loss: tensor(0.0807, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.6115, -0.2060]])\n","\n","loss: tensor(0.0811, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.6244, -0.2072]])\n","\n","loss: tensor(0.0815, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.6375, -0.2084]])\n","\n","loss: tensor(0.0819, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.6506, -0.2096]])\n","\n","loss: tensor(0.0823, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.6638, -0.2109]])\n","\n","loss: tensor(0.0827, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.6771, -0.2121]])\n","\n","loss: tensor(0.0830, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.6905, -0.2134]])\n","\n","loss: tensor(0.0834, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.7040, -0.2147]])\n","\n","loss: tensor(0.0838, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.7176, -0.2160]])\n","\n","loss: tensor(0.0842, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.7313, -0.2172]])\n","\n","loss: tensor(0.0846, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.7451, -0.2185]])\n","\n","loss: tensor(0.0850, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.7589, -0.2198]])\n","\n","loss: tensor(0.0854, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.7729, -0.2212]])\n","\n","loss: tensor(0.0859, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.7870, -0.2225]])\n","\n","loss: tensor(0.0863, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.8011, -0.2238]])\n","\n","loss: tensor(0.0867, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.8154, -0.2252]])\n","\n","loss: tensor(0.0871, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.8297, -0.2265]])\n","\n","loss: tensor(0.0875, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.8442, -0.2279]])\n","\n","loss: tensor(0.0879, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.8588, -0.2292]])\n","\n","loss: tensor(0.0883, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.8734, -0.2306]])\n","\n","loss: tensor(0.0888, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.8882, -0.2320]])\n","\n","loss: tensor(0.0892, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.9031, -0.2334]])\n","\n","loss: tensor(0.0896, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.9181, -0.2348]])\n","\n","loss: tensor(0.0901, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.9332, -0.2362]])\n","\n","loss: tensor(0.0905, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.9484, -0.2377]])\n","\n","loss: tensor(0.0909, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.9637, -0.2391]])\n","\n","loss: tensor(0.0914, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.9791, -0.2406]])\n","\n","loss: tensor(0.0918, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-2.9947, -0.2420]])\n","\n","loss: tensor(0.0922, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.0103, -0.2435]])\n","\n","loss: tensor(0.0927, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.0261, -0.2450]])\n","\n","loss: tensor(0.0931, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.0420, -0.2465]])\n","\n","loss: tensor(0.0936, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.0580, -0.2480]])\n","\n","loss: tensor(0.0941, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.0741, -0.2495]])\n","\n","loss: tensor(0.0945, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.0903, -0.2510]])\n","\n","loss: tensor(0.0950, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.1067, -0.2525]])\n","\n","loss: tensor(0.0954, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.1232, -0.2541]])\n","\n","loss: tensor(0.0959, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.1398, -0.2557]])\n","\n","loss: tensor(0.0964, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.1565, -0.2572]])\n","\n","loss: tensor(0.0969, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.1734, -0.2588]])\n","\n","loss: tensor(0.0973, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.1904, -0.2604]])\n","\n","loss: tensor(0.0978, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.2075, -0.2620]])\n","\n","loss: tensor(0.0983, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.2247, -0.2636]])\n","\n","loss: tensor(0.0988, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.2421, -0.2653]])\n","\n","loss: tensor(0.0993, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.2596, -0.2669]])\n","\n","loss: tensor(0.0998, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.2773, -0.2686]])\n","\n","loss: tensor(0.1003, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.2951, -0.2702]])\n","\n","loss: tensor(0.1008, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.3130, -0.2719]])\n","\n","loss: tensor(0.1013, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.3311, -0.2736]])\n","\n","loss: tensor(0.1018, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.3493, -0.2753]])\n","\n","loss: tensor(0.1023, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.3676, -0.2771]])\n","\n","loss: tensor(0.1028, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.3861, -0.2788]])\n","\n","loss: tensor(0.1033, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.4048, -0.2806]])\n","\n","loss: tensor(0.1038, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.4236, -0.2823]])\n","\n","loss: tensor(0.1044, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.4425, -0.2841]])\n","\n","loss: tensor(0.1049, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.4616, -0.2859]])\n","\n","loss: tensor(0.1054, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.4809, -0.2877]])\n","\n","loss: tensor(0.1060, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.5003, -0.2895]])\n","\n","loss: tensor(0.1065, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.5199, -0.2914]])\n","\n","loss: tensor(0.1071, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.5396, -0.2932]])\n","\n","loss: tensor(0.1076, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.5595, -0.2951]])\n","\n","loss: tensor(0.1082, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.5795, -0.2970]])\n","\n","loss: tensor(0.1087, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.5998, -0.2989]])\n","\n","loss: tensor(0.1093, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.6201, -0.3008]])\n","\n","loss: tensor(0.1099, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.6407, -0.3027]])\n","\n","loss: tensor(0.1104, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.6614, -0.3046]])\n","\n","loss: tensor(0.1110, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.6823, -0.3066]])\n","\n","loss: tensor(0.1116, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.7034, -0.3086]])\n","\n","loss: tensor(0.1122, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.7247, -0.3106]])\n","\n","loss: tensor(0.1128, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.7461, -0.3126]])\n","\n","loss: tensor(0.1134, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.7678, -0.3146]])\n","\n","loss: tensor(0.1140, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.7896, -0.3167]])\n","\n","loss: tensor(0.1146, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.8116, -0.3187]])\n","\n","loss: tensor(0.1152, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.8338, -0.3208]])\n","\n","loss: tensor(0.1158, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.8562, -0.3229]])\n","\n","loss: tensor(0.1165, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.8788, -0.3250]])\n","\n","loss: tensor(0.1171, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.9016, -0.3272]])\n","\n","loss: tensor(0.1177, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.9246, -0.3293]])\n","\n","loss: tensor(0.1184, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.9478, -0.3315]])\n","\n","loss: tensor(0.1190, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.9712, -0.3337]])\n","\n","loss: tensor(0.1197, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-3.9948, -0.3359]])\n","\n","loss: tensor(0.1203, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.0186, -0.3381]])\n","\n","loss: tensor(0.1210, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.0427, -0.3404]])\n","\n","loss: tensor(0.1217, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.0669, -0.3427]])\n","\n","loss: tensor(0.1223, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.0914, -0.3450]])\n","\n","loss: tensor(0.1230, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.1161, -0.3473]])\n","\n","loss: tensor(0.1237, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.1411, -0.3496]])\n","\n","loss: tensor(0.1244, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.1662, -0.3520]])\n","\n","loss: tensor(0.1251, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.1917, -0.3544]])\n","\n","loss: tensor(0.1258, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.2173, -0.3568]])\n","\n","loss: tensor(0.1266, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.2432, -0.3592]])\n","\n","loss: tensor(0.1273, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.2694, -0.3616]])\n","\n","loss: tensor(0.1280, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.2958, -0.3641]])\n","\n","loss: tensor(0.1288, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.3224, -0.3666]])\n","\n","loss: tensor(0.1295, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.3493, -0.3691]])\n","\n","loss: tensor(0.1303, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.3765, -0.3716]])\n","\n","loss: tensor(0.1311, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.4039, -0.3742]])\n","\n","loss: tensor(0.1318, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.4316, -0.3768]])\n","\n","loss: tensor(0.1326, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.4596, -0.3794]])\n","\n","loss: tensor(0.1334, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.4879, -0.3821]])\n","\n","loss: tensor(0.1342, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.5164, -0.3847]])\n","\n","loss: tensor(0.1350, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.5452, -0.3874]])\n","\n","loss: tensor(0.1358, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.5744, -0.3901]])\n","\n","loss: tensor(0.1367, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.6038, -0.3929]])\n","\n","loss: tensor(0.1375, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.6335, -0.3956]])\n","\n","loss: tensor(0.1384, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.6635, -0.3985]])\n","\n","loss: tensor(0.1392, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.6938, -0.4013]])\n","\n","loss: tensor(0.1401, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.7245, -0.4041]])\n","\n","loss: tensor(0.1410, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.7554, -0.4070]])\n","\n","loss: tensor(0.1419, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.7867, -0.4099]])\n","\n","loss: tensor(0.1428, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.8183, -0.4129]])\n","\n","loss: tensor(0.1437, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.8503, -0.4159]])\n","\n","loss: tensor(0.1446, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.8826, -0.4189]])\n","\n","loss: tensor(0.1456, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.9152, -0.4219]])\n","\n","loss: tensor(0.1465, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.9482, -0.4250]])\n","\n","loss: tensor(0.1475, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.9816, -0.4281]])\n","\n","loss: tensor(0.1485, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.0153, -0.4312]])\n","\n","loss: tensor(0.1495, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.0494, -0.4344]])\n","\n","loss: tensor(0.1505, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.0838, -0.4376]])\n","\n","loss: tensor(0.1515, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.1187, -0.4408]])\n","\n","loss: tensor(0.1525, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.1539, -0.4441]])\n","\n","loss: tensor(0.1536, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.1895, -0.4474]])\n","\n","loss: tensor(0.1546, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.2256, -0.4508]])\n","\n","loss: tensor(0.1557, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.2620, -0.4542]])\n","\n","loss: tensor(0.1568, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.2988, -0.4576]])\n","\n","loss: tensor(0.1579, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.3361, -0.4610]])\n","\n","loss: tensor(0.1591, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.3738, -0.4645]])\n","\n","loss: tensor(0.1602, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.4119, -0.4681]])\n","\n","loss: tensor(0.1614, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.4505, -0.4717]])\n","\n","loss: tensor(0.1626, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.4895, -0.4753]])\n","\n","loss: tensor(0.1638, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.5290, -0.4789]])\n","\n","loss: tensor(0.1650, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.5689, -0.4826]])\n","\n","loss: tensor(0.1663, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.6093, -0.4864]])\n","\n","loss: tensor(0.1675, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.6502, -0.4902]])\n","\n","loss: tensor(0.1688, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.6916, -0.4940]])\n","\n","loss: tensor(0.1701, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.7334, -0.4979]])\n","\n","loss: tensor(0.1715, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.7758, -0.5018]])\n","\n","loss: tensor(0.1728, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.8186, -0.5057]])\n","\n","loss: tensor(0.1742, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.8620, -0.5097]])\n","\n","loss: tensor(0.1756, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.9059, -0.5138]])\n","\n","loss: tensor(0.1771, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.9504, -0.5179]])\n","\n","loss: tensor(0.1785, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.9953, -0.5220]])\n","\n","loss: tensor(0.1800, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.0408, -0.5262]])\n","\n","loss: tensor(0.1815, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.0869, -0.5305]])\n","\n","loss: tensor(0.1831, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.1335, -0.5348]])\n","\n","loss: tensor(0.1847, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.1807, -0.5391]])\n","\n","loss: tensor(0.1863, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.2285, -0.5435]])\n","\n","loss: tensor(0.1880, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.2768, -0.5480]])\n","\n","loss: tensor(0.1896, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.3257, -0.5525]])\n","\n","loss: tensor(0.1914, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.3752, -0.5571]])\n","\n","loss: tensor(0.1931, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.4253, -0.5617]])\n","\n","loss: tensor(0.1949, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.4760, -0.5663]])\n","\n","loss: tensor(0.1968, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.5273, -0.5711]])\n","\n","loss: tensor(0.1987, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.5792, -0.5758]])\n","\n","loss: tensor(0.2006, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.6318, -0.5807]])\n","\n","loss: tensor(0.2026, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.6849, -0.5855]])\n","\n","loss: tensor(0.2046, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.7386, -0.5905]])\n","\n","loss: tensor(0.2067, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.7929, -0.5955]])\n","\n","loss: tensor(0.2088, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.8478, -0.6005]])\n","\n","loss: tensor(0.2110, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.9033, -0.6056]])\n","\n","loss: tensor(0.2133, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.9594, -0.6107]])\n","\n","loss: tensor(0.2156, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.0161, -0.6159]])\n","\n","loss: tensor(0.2179, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.0733, -0.6212]])\n","\n","loss: tensor(0.2204, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.1311, -0.6265]])\n","\n","loss: tensor(0.2229, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.1894, -0.6319]])\n","\n","loss: tensor(0.2255, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.2482, -0.6372]])\n","\n","loss: tensor(0.2281, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.3075, -0.6427]])\n","\n","loss: tensor(0.2309, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.3672, -0.6482]])\n","\n","loss: tensor(0.2337, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.4273, -0.6537]])\n","\n","loss: tensor(0.2367, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.4878, -0.6592]])\n","\n","loss: tensor(0.2397, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.5485, -0.6648]])\n","\n","loss: tensor(0.2428, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.6095, -0.6704]])\n","\n","loss: tensor(0.2461, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.6707, -0.6761]])\n","\n","loss: tensor(0.2495, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.7319, -0.6817]])\n","\n","loss: tensor(0.2529, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.7932, -0.6873]])\n","\n","loss: tensor(0.2566, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.8543, -0.6930]])\n","\n","loss: tensor(0.2603, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.9151, -0.6986]])\n","\n","loss: tensor(0.2642, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.9755, -0.7042]])\n","\n","loss: tensor(0.2683, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.0354, -0.7097]])\n","\n","loss: tensor(0.2726, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.0944, -0.7152]])\n","\n","loss: tensor(0.2770, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.1525, -0.7206]])\n","\n","loss: tensor(0.2817, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.2093, -0.7259]])\n","\n","loss: tensor(0.2866, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.2645, -0.7310]])\n","\n","loss: tensor(0.2917, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.3178, -0.7361]])\n","\n","loss: tensor(0.2970, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.3688, -0.7409]])\n","\n","loss: tensor(0.3027, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.4170, -0.7455]])\n","\n","loss: tensor(0.3087, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.4620, -0.7498]])\n","\n","loss: tensor(0.3150, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.5030, -0.7538]])\n","\n","loss: tensor(0.3217, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.5395, -0.7574]])\n","\n","loss: tensor(0.3287, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.5706, -0.7605]])\n","\n","loss: tensor(0.3363, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.5953, -0.7631]])\n","\n","loss: tensor(0.3444, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.6127, -0.7651]])\n","\n","loss: tensor(0.3530, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.6215, -0.7663]])\n","\n","loss: tensor(0.3623, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.6202, -0.7667]])\n","\n","loss: tensor(0.3724, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.6072, -0.7661]])\n","\n","loss: tensor(0.3833, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.5806, -0.7642]])\n","\n","loss: tensor(0.3951, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.5382, -0.7610]])\n","\n","loss: tensor(0.4081, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.4773, -0.7562]])\n","\n","loss: tensor(0.4224, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.3951, -0.7494]])\n","\n","loss: tensor(0.4383, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.2881, -0.7404]])\n","\n","loss: tensor(0.4561, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-8.1521, -0.7289]])\n","\n","loss: tensor(0.4762, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.9825, -0.7142]])\n","\n","loss: tensor(0.4993, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.7736, -0.6960]])\n","\n","loss: tensor(0.5260, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.5187, -0.6735]])\n","\n","loss: tensor(0.5575, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-7.2095, -0.6460]])\n","\n","loss: tensor(0.5956, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.8356, -0.6124]])\n","\n","loss: tensor(0.6431, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-6.3828, -0.5713]])\n","\n","loss: tensor(0.7049, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.8306, -0.5207]])\n","\n","loss: tensor(0.7907, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-5.1473, -0.4571]])\n","\n","loss: tensor(0.9251, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[ 0.0000,  1.0000],\n","        [-4.3138, -0.3731]])\n","\n","loss: tensor(1.2171, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n","\n","Jacobian matrix initial: tensor([[-0.0000,  1.0000],\n","        [-9.8100, -0.4000]])\n","Jacobian matrix initial NN: tensor([[nan, nan],\n","        [nan, nan]])\n","\n","loss: tensor(nan, grad_fn=<AbsBackward0>)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-b7158950d3e4>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mJ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpendulum_dynamics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m       \u001b[0mJ0_NN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate0_NN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m       \u001b[0mJ1_NN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate1_NN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[0m\u001b[1;32m    593\u001b[0m                                               \u001b[0;34m\"outputs of the user-provided function\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                                               \"jacobian\")\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36m_as_tuple\u001b[0;34m(inp, arg_name, fn_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_as_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Ensures that inp is a tuple of Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Returns whether or not the original inp was a tuple and the tupled version of the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Initialize the PINN model\n","model = PINN()\n","torch.save(model.state_dict(), 'model_weights.pth')  \n","\n","# Initialize optimizer and learning rate\n","learning_rate = 1e-5\n","# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, amsgrad=True)\n","\n","num_epochs = 100\n","\n","for epoch in tqdm(range(1,num_epochs+1)):    \n","  torch.save(model.state_dict(), 'model_weights.pth')  \n","  t = np.arange(t0, tmax, dt)\n","  theta = np.zeros_like(t)\n","  omega = np.zeros_like(t)\n","  theta_dot = np.zeros_like(t)\n","  omega_dot = np.zeros_like(t)\n","  theta_NN = np.zeros_like(t)\n","  omega_NN = np.zeros_like(t)\n","  theta_dot_NN = np.zeros_like(t)\n","  omega_dot_NN = np.zeros_like(t)\n","  Loss = np.zeros_like(t)\n","  residual = np.zeros_like(t)\n","  residual_NN = np.zeros_like(t)\n","  theta[0] = 0.01*torch.pi*torch.randn(1).item()\n","  omega[0] = 0.001*torch.randn(1).item()\n","  theta_NN[0] = theta[0]\n","  omega_NN[0] = omega[0]\n","\n","  flag=True\n","  for i in tqdm(range(1,len(t))):\n","      # Previous true and estimated solutions of the ODEs\n","      state0 = torch.tensor( [theta[i-1], omega[i-1]],  dtype=torch.float32) \n","      state0_NN = torch.tensor( [theta_NN[i-1], omega_NN[i-1]],  dtype=torch.float32)\n","\n","      # if epoch%5==0:\n","      #       state0_NN = state0 \n","      #       if flag: print('Using Pendulum'); flag=False\n","      # else:\n","      #       state0_NN = torch.tensor( [theta_NN[i-1], omega_NN[i-1]],  dtype=torch.float32)\n","      #       if flag: print('Using PINN'); flag=False\n","\n","      #### Step once ####\n","      model.eval()\n","      optimizer.zero_grad()\n","      model.load_state_dict(torch.load('model_weights.pth'))\n","      # v1, omega[i] = state1 = state0 + pendulum_dynamics(state0)*dt           # 1st order Runge-Kutta Integration (Forward Euler)\n","      # v1_NN, omega_NN[i] = state1_NN = state0_NN + model(state0_NN)*dt        # 1st order Runge-Kutta Integration (Forward Euler)       \n","      v1, omega[i] = state1 = rungekutta4_step(pendulum_dynamics, state0, dt)   # 4th order Runge-Kutta Integration \n","      v1_NN, omega_NN[i] = state1_NN = rungekutta4_step(model, state0_NN, dt)   # 4th order Runge-Kutta Integration \n","\n","      theta[i] = theta1 = torch.asin(v1)\n","      theta_NN[i] = theta1_NN = torch.asin(v1_NN)\n","\n","      model.train()\n","      optimizer.zero_grad()\n","      \n","      f0 = pendulum_dynamics(state0)\n","      f1 = pendulum_dynamics(state1)\n","\n","      f0_NN = model(state0)\n","      f1_NN = model(state1)\n","\n","      J0 = torch.autograd.functional.jacobian(pendulum_dynamics, state0)\n","      J1 = torch.autograd.functional.jacobian(pendulum_dynamics, state1)\n","      \n","      J0_NN = torch.autograd.functional.jacobian(model, state0_NN)\n","      J1_NN = torch.autograd.functional.jacobian(model, state1_NN)\n","\n","      theta_dot[i], omega_dot[i] = Jf0 = torch.matmul(J0, state0)\n","      theta_dot_NN[i], omega_dot_NN[i] = Jf0_NN = torch.matmul(J0_NN, state0_NN)\n","      \n","      Jf1 = torch.matmul(J1, state1)\n","      Jf1_NN = torch.matmul(J1_NN, state1_NN)\n","\n","      # compute the mean squared error loss      \n","      # loss = nn.HuberLoss(reduction='mean', delta=0.5)(theta1, theta1_NN)\n","      loss = torch.abs(theta1-theta1_NN) \n","      # loss += nn.MSELoss()(Jf1, Jf1_NN) \n","      # loss += nn.MSELoss()(f0, f0_NN)\n","      # loss += nn.MSELoss()(f1, f1_NN)\n","      # loss += nn.MSELoss()(J0, J0_NN)\n","      # loss += nn.MSELoss()(J1, J1_NN)\n","      # compute the Jacobian matrix loss\n","\n","      # Compute Jacobian matrix and its norm\n","      J0_norm = torch.norm(J0_NN.view(-1), p=3)\n","      L = 1.\n","      # Add Lipschitz penalty to the loss\n","      lipschitz_penalty = L * (J0_norm - 10.0)\n","      # loss += lipschitz_penalty\n","\n","      # Backward pass and gradient clipping\n","      loss.backward(retain_graph=True)\n","      # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n","      optimizer.step()\n","  \n","      torch.save(model.state_dict(), 'model_weights.pth')  \n","      Loss[i] = loss.item()\n","      # print('\\nJacobian matrix initial:', J0)\n","      # print('Jacobian matrix initial NN:', J0_NN)\n","      print('\\nloss:', loss)\n","\n","  # print('\\nInitial state:', state0)\n","  # print('New state:', state1)\n","  # print('New state NN:', state1_NN)\n","\n","  # print('\\nDynamics at initial state:', f0)\n","  # print('Dynamics at initial state NN:', f0_NN)\n","  # print('Dynamics at new state:', f1)\n","  # print('Dynamics at new state NN:', f1_NN)\n","\n","  # print('\\nJacobian matrix initial:', J0)\n","  # print('Jacobian matrix initial NN:', J0_NN)\n","  # print('Jacobian matrix new:', J1)\n","  # print('Jacobian matrix new NN:', J1_NN)\n","\n","  # print('$\\Theta$:', theta1)\n","  # print('$\\Theta$_NN:', theta1_NN)\n","\n","  # print('\\nJacobian*initial_state:', Jf0)\n","  # print('Jacobian NN*initial_state:', Jf1)\n","  # print('Jacobian*new_state:', Jf0_NN)\n","  # print('Jacobian NN*new_state_NN:', Jf1_NN)\n","\n","  fig, axs = plt.subplots(nrows=6, ncols=1, sharex=True, figsize=(20,30))\n","\n","  axs[0].plot(theta, label='$\\Theta$')\n","  axs[0].plot(theta_NN, '--', label='$\\Theta$_NN')\n","  axs[0].set_ylabel('Amplitude')\n","  axs[0].legend(loc='best')\n","  axs[0].grid(True)\n","  axs[0].set_title(f'epoch:{epoch}/{num_epochs} loss:{Loss[i]}')\n","\n","  axs[1].plot(omega, label='$\\Omega$')\n","  axs[1].plot(omega_NN, '--', label='$\\Omega$_NN')\n","  axs[1].set_ylabel('Amplitude')\n","  axs[1].legend(loc='best')\n","  axs[1].grid(True)\n","  # axs[1].set_title(f'epoch:{epoch}/{num_epochs} loss:{Loss[i]}')\n","\n","  axs[2].plot(theta_dot, label='$\\theta$_dot')\n","  axs[2].plot(theta_dot_NN, '--', label='$\\theta$_dot_NN')\n","  axs[2].set_ylabel('$dot{\\Omega}$')\n","  axs[2].legend(loc='best')\n","  axs[2].grid(True)\n","  # axs[2].set_title(f'epoch:{epoch}/{num_epochs} loss:{Loss[i]}')\n","\n","  axs[3].plot(omega_dot, label='$\\Omega$_dot')\n","  axs[3].plot(omega_dot_NN, '--', label='$\\Omega$_dot_NN')\n","  axs[3].set_ylabel('$dot{\\Omega}$')\n","  axs[3].legend(loc='best')\n","  axs[3].grid(True)\n","  # axs[3].set_title(f'epoch:{epoch}/{num_epochs} loss:{Loss[i]}')\n","\n","  axs[4].plot(residual, label='Residual_actual')\n","  axs[4].plot(residual_NN, '--', label='Residual_pred')\n","  axs[4].set_ylabel('Residual')\n","  axs[4].legend(loc='best')\n","  axs[4].grid(True)\n","  # axs[4].set_title(f'epoch:{epoch}/{num_epochs} loss:{Loss[i]}')\n","\n","  axs[5].plot(Loss, label='Loss')\n","  # axs[5].set_xlabel('Time')\n","  axs[5].set_ylabel('Loss')\n","  axs[5].legend(loc='best')\n","  axs[5].grid(True)\n","  # axs[5].set_title(f'epoch:{epoch}/{num_epochs} loss:{Loss[i]}')\n","\n","  plt.tight_layout()\n","  plt.show()"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1681473188288,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"c2vJuPqIiGIY"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1DkV60WWdWU0p4fZNDckVvybgR4FF-Pze","timestamp":1678060439742}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"be39d3cbac794beeb23d06e7868e5dc5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc7ea469bb7d4e2990368b89482d7b4e","IPY_MODEL_9cffb32eba2d472ab82b6470cb011417","IPY_MODEL_7aaa8d10453d437084d4f5cef5c88c99"],"layout":"IPY_MODEL_c69a4800b38f44e39e796d9451e8bd55"}},"fc7ea469bb7d4e2990368b89482d7b4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b4c4a23b1c04d13a3ab1890761721c0","placeholder":"​","style":"IPY_MODEL_1e4562299a4c4930a43e1a5b8ed5fe3d","value":"  0%"}},"9cffb32eba2d472ab82b6470cb011417":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2b608b45c7642bdacc8cc9d21cfb8a3","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c0e9f216d3f4ef2b38a232aa2562456","value":0}},"7aaa8d10453d437084d4f5cef5c88c99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1fc1dda3f7e41929d84c603e627e369","placeholder":"​","style":"IPY_MODEL_888bc668c87c4cb68c5ccea2bdc52630","value":" 0/100 [03:10&lt;?, ?it/s]"}},"c69a4800b38f44e39e796d9451e8bd55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b4c4a23b1c04d13a3ab1890761721c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e4562299a4c4930a43e1a5b8ed5fe3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2b608b45c7642bdacc8cc9d21cfb8a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c0e9f216d3f4ef2b38a232aa2562456":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1fc1dda3f7e41929d84c603e627e369":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"888bc668c87c4cb68c5ccea2bdc52630":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5401f892d444da5b69e41387ce11a29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2fcea0e5f2be4ceb83753bc6edbb8f65","IPY_MODEL_292f03a9c29749048ff0e5193aa8838e","IPY_MODEL_12836d060cec4d16bbc246f2b708c940"],"layout":"IPY_MODEL_727068d0f957410c812ed9a812a95251"}},"2fcea0e5f2be4ceb83753bc6edbb8f65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b285579f36504478bd72fdfba46d7906","placeholder":"​","style":"IPY_MODEL_d671527d3a4346a7812a86c91584f431","value":" 14%"}},"292f03a9c29749048ff0e5193aa8838e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd7dbceccc274d3aad7525773d1a42f7","max":7999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0491128113d346478f53e9a51ae911ac","value":1141}},"12836d060cec4d16bbc246f2b708c940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d57074bbb9e64e4dba4c6c03a3734984","placeholder":"​","style":"IPY_MODEL_86f61fbccbe24c078cdab4acb5c5ab28","value":" 1141/7999 [03:10&lt;19:06,  5.98it/s]"}},"727068d0f957410c812ed9a812a95251":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b285579f36504478bd72fdfba46d7906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d671527d3a4346a7812a86c91584f431":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd7dbceccc274d3aad7525773d1a42f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0491128113d346478f53e9a51ae911ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d57074bbb9e64e4dba4c6c03a3734984":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86f61fbccbe24c078cdab4acb5c5ab28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}